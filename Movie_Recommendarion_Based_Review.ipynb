{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1pwVBCpNCoh0se69lTMxxELfy3IJHQOhi","authorship_tag":"ABX9TyMzUJclkTJOflKdZ2bd4lJN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"-5TlHdXEXLUh"},"outputs":[],"source":["from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","from nltk.tag import pos_tag\n","from nltk.stem import PorterStemmer, WordNetLemmatizer\n","from nltk.probability import FreqDist\n","from nltk.classify import NaiveBayesClassifier, accuracy\n","\n","from sklearn.feature_extraction.text import TfIdfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","from IPython.display import clear_output\n","\n","import pandas as pd\n","import string\n","import pickle\n","import spacy\n","import random"]},{"cell_type":"code","source":["import nltk\n","nltk.download('stopwords')\n","\n","import nltk\n","nltk.download('punkt')\n","\n","import nltk\n","nltk.download('averaged_perceptron_tagger')\n","\n","import nltk\n","nltk.download('wordnet')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5bgp51nqN8VW","executionInfo":{"status":"ok","timestamp":1718410011880,"user_tz":-420,"elapsed":4561,"user":{"displayName":"Janssen Mitchellano","userId":"11943451001673037110"}},"outputId":"8da14e56-8fb9-4c10-e733-3de0e48c6e3b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":["def enter_to_continue():\n","    input(\"Press Enter to continue...\")"],"metadata":{"id":"1I6tOa510DWJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["clssifier = None\n","review = \"\"\n","category = \"\"\n","\n","def load_dataset():\n","  df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/NLP_Lab_Quiz/movie-review.csv\")\n","  return df\n","\n","def get_tag(tag):\n","  if tag == 'j':\n","    return 'a'\n","  elif tag in ['nn', 'vb', 'rb']:\n","    return tag[0]\n","  else:\n","    return None\n","\n","def preprocess(word_list):\n","  word_list = [word for word in word_list if word not in stopwords.words('english')]\n","  word_list = [word for word in word_list if word not in string.punctuation]\n","  word_list = [word for word in word_list if word.isalpha()]\n","\n","  stemming = PorterStemmer()\n","  word_list = [stemming.stem(word) for word in word_list]\n","\n","  tagging = pos_tag(word_list)\n","  wnl = WordNetLemmatizer()\n","  word_list = [wnl.lemmatize(word, pos = get_tag(tag)) for word, tag in tagging]\n","\n","  return word_list"],"metadata":{"id":"jCxr-bphZDvJ","executionInfo":{"status":"ok","timestamp":1718417851724,"user_tz":-420,"elapsed":2,"user":{"displayName":"Janssen Mitchellano","userId":"11943451001673037110"}}},"execution_count":88,"outputs":[]},{"cell_type":"code","source":["def train_model():\n","  df = load_model().sample(n=3000)\n","\n","  review_list = [str(review) for review in df['review'].to_list()]\n","  sentiment_list = [str(sentiment) for sentiment in df['sentimentScore'].to_list()]\n","\n","  word_list = []\n","\n","  for sentence in review_list:\n","    words = word_tokenize(sentence)\n","    for word in words:\n","      word_list.append(word.lower())\n","\n","  word_list = preprocess(word_list)\n","\n","  labeled_data = list(zip(review_list, sentiment_list))\n","\n","  feature_sets = []\n","\n","  for review, sentiment in labeled_data:\n","    feature = {}\n","\n","    check_word = word_tokenize(review)\n","    check_word = preprocess(check_word)\n","\n","    for word in word_list:\n","      feature[word] = word in check_word\n","\n","    feature_sets.append((feature, sentiment))\n","\n","  random.shufle()\n","\n","  train_count = int(len(feature_sets))\n","  train_dataset = feature_sets[:train_count]\n","  test_dataset = feature_sets[train_count:]\n","\n","  classifier = NaiveBayesClassifier(train_dataset)\n","  print(f\"Accuracy : {accuracy(classifier, test_dataset)}\")\n","\n","  file = open('model.pickle', 'wb')\n","  pickle.dump(classifier, file)\n","  file.close()\n","\n","  return classifier"],"metadata":{"id":"JY3K42kAbhAo","executionInfo":{"status":"ok","timestamp":1718417848911,"user_tz":-420,"elapsed":1335,"user":{"displayName":"Janssen Mitchellano","userId":"11943451001673037110"}}},"execution_count":87,"outputs":[]},{"cell_type":"code","source":["def print_menu():\n","  global review\n","  display_review = \"No review\"\n","  global category\n","  display_category = \"None\"\n","\n","  if display_review != \"\":\n","    review = display_review\n","\n","  if display_category != \"\":\n","    category = display_category\n","\n","  print(\"Movie Recommendation Based on reviews\")\n","  print(f\"Your review : {display_review}\")\n","  print(f\"Review category ; {display_category}\")\n","  print(\"1. Input review\")\n","  print(\"2. View movie recommendation\")\n","  print(\"3. view ner\")\n","  print(\"4. Exit\")\n","  choice = input(\">> \")\n","  return choice"],"metadata":{"id":"7eIlS3x1zjzX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def write_review():\n","  clear_output()\n","\n","  global review\n","  global category\n","  global classifier\n","  print(\"Input your review\")\n","  review_input = input(\">> \")\n","\n","  if len(review_input.split(' ')) < 20:\n","    print(\"review must atleast contain 20 words\")\n","    enter_to_continue()\n","    return\n","\n","  review = review_input\n","\n","  words = word_tokenize(review_input)\n","  words = preprocess(words)\n","\n","  feature = FreqDist(words)\n","  category = classifier.classify(feature)\n","\n","  print(f\"Review Classified as {category}\")\n","\n","  enter_to_continue()\n"],"metadata":{"id":"4z8kTIcJz2A9","executionInfo":{"status":"ok","timestamp":1718418223793,"user_tz":-420,"elapsed":717,"user":{"displayName":"Janssen Mitchellano","userId":"11943451001673037110"}}},"execution_count":92,"outputs":[]},{"cell_type":"code","source":["def view_movie_recommendation():\n","  clear_output()\n","\n","  global review\n","  df = load_dataset()\n","\n","  review_list = [str(review) for review in df['review'].to_list()]\n","  title_list = [str(title) for title in df['title'].to_list()]\n","\n","  vectorizer = TfidfVectorizer()\n","  matrix = vectorizer.fit_transform(review_list)\n","\n","  query_matrix = vectorizer.transform([review])\n","  cosine_similarities = cosine_similarity(query_matrix, matrix).flatten()\n","\n","  related_docs_indices = cosine_similarities.argsort()[::-1][:3]\n","\n","  for i, idx in enumerate(related_docs_indices):\n","    print(f\"{i+1}. {title_list[idx]}\")\n","  enter_to_continue()"],"metadata":{"id":"Bdek5Eox2A9C","executionInfo":{"status":"ok","timestamp":1718418254109,"user_tz":-420,"elapsed":12805,"user":{"displayName":"Janssen Mitchellano","userId":"11943451001673037110"}}},"execution_count":93,"outputs":[]},{"cell_type":"code","source":["# def view_ner():\n","#     clear_output()\n","\n","#     df = load_dataset().sample(n=3000)\n","#     reviews = df['review'].to_string()\n","\n","#     spacy_nlp = spacy.load('en_core_web_sm')\n","#     doc = spacy_nlp(reviews)\n","\n","#     categories = {}\n","\n","#     for ent in doc.ents:\n","#         label = ent.label_\n","\n","#         if label not in ['LANGUAGE', 'GPE']:\n","#             continue\n","\n","#         if label not in categories:\n","#             categories[label] = []\n","\n","#         categories[label].append(ent.text)\n","\n","#     for label, entities in categories.items():\n","#         print(f\"{label}: {', '.join(entities)}\")\n","\n","#     if len(categories) == 0:\n","#         print(\"No entities found\")\n","\n","#     enter_to_continue()\n","\n","def view_ner():\n","  clear_output()\n","\n","  df = load_dataset().sample(n=3000)\n","  review_string = df['review'].to_string()\n","\n","  spacy_nlp = spacy.load('en_core_web_sm')\n","  doc = spacy_nlp(review_string)\n","\n","  categories = {}\n","\n","  for ent in doc.ents:\n","    label = ent.label_\n","\n","    if label not in ['LANGUAGE', 'GPE']:\n","      continue\n","\n","    if label not in categories:\n","      categories[label] = []\n","\n","    categories[label].append(ent.text)\n","\n","  for label, entities in categories.item():\n","    print(f\"{label} : {', '.join(entities)}\")\n","\n","  if len(categories) == 0:\n","    print(\"No entities found\")\n","  enter_to_continue()"],"metadata":{"id":"8Oix1kCX2DFm","executionInfo":{"status":"ok","timestamp":1718417986738,"user_tz":-420,"elapsed":6077,"user":{"displayName":"Janssen Mitchellano","userId":"11943451001673037110"}}},"execution_count":89,"outputs":[]},{"cell_type":"code","source":["def main():\n","    global classifier\n","    # try:\n","    #     file = open('model.pickle', 'rb')\n","    #     classifier = pickle.load(file)\n","    #     file.close()\n","    # except FileNotFoundError:\n","    #     classifier = train_model()\n","    try:\n","      file = open('model.pickle', 'rb')\n","      classifier = pickle.load(file)\n","      file.close()\n","    except FileNotFoundError:\n","      classifier = train_model()\n","\n","    while True:\n","        clear_output()\n","        choice = print_menu()\n","        if choice == '1':\n","            write_review()\n","        elif choice == '2':\n","            view_movie_recommendation()\n","        elif choice == '3':\n","            view_ner()\n","        elif choice == '4':\n","            break\n","\n","    print(\"Goodbye!\")"],"metadata":{"id":"Hy9UbGsAMA9u","executionInfo":{"status":"ok","timestamp":1718414745436,"user_tz":-420,"elapsed":544,"user":{"displayName":"Janssen Mitchellano","userId":"11943451001673037110"}}},"execution_count":82,"outputs":[]},{"cell_type":"code","source":["# main()"],"metadata":{"id":"3ZOTyvnGMJ0u"},"execution_count":null,"outputs":[]}]}